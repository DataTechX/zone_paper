\subsubsection{Model}

In order to evaluate in which contexts supersymmetry arises within the high-energy physics literature, we have chosen to subdivide the literature into sub-topics using an unsupervised probabilistic topic model, namely the Correlated Topic Model (CTM, \citealt{Blei2007}). We do not use conventional classifications such as the \gls{pacs} codes from the\gls{aip}, because they were not available for the whole dataset -- \gls{pacs} codes were only available starting from 1995, and only for a subset of the papers, which may not be representative of the whole. Besides, \gls{pacs} codes are too numerous (more than 5000 categories)\footnote{``Full list of PACS numbers'', \textit{
Physics-Uspekhi}, \url{https://ufn.ru/en/pacs/all/}} for our purposes. Therefore, we opted to extract the topics in the literature using unsupervised topic models instead. %In our case, since we would like to develop and probe methods that may be applied more systematically to other domains, including those for which such classification schemes may be lacking, it seemed more relevant to avoid using those categories at all. For this reason, we have decided to resort to unsupervised classification methods, i.e. methods that learn topics from the data (in our case, from the abstracts of the papers, since the full texts are not consistently available). 

Probabilistic topic models generally assume that each document of a corpus is a mixture of variable proportions of a certain amount of topics, each of these topics having their own vocabulary distribution. When trained on a corpus, such models simultaneously learn the ``topics'' in the corpus (and their vocabulary), as well as the relative contribution of each topic to each document of the corpus. These models have demonstrated their ability to capture the semantic information contained within the scientific and academic literature, as shown in previous work\footnote{Notable examples are \citealt{Nichols2014,Hall2008,Griffiths2004}; see \citealt{Malaterre2022} for a more recent application in the context of History and Philosophy of Science, and \citealt{Allen2022} for an assessment of the potential and limitations of these methods in the field.}, even from abstracts alone \citep{Syed2017}; as a result this technique has seemingly taken precedence over network-based semantic maps \citep[Figure~1]{Leydesdorff2016}. Topic models provide a straightforward derivation of the information that is of interest to us: the vocabulary associated to each ``topic'', and the contribution of each ``topic'' to each document of a corpus. Although co-occurrence networks may have more conceptual bearing in the STS tradition, we have preferred topic models for their intrinsic ability to capture the polysemy of certain words (e.g., ``supersymmetry''), in terms of the probabilities that such words can arise in different contexts (i.e. topics).

In particular, we have chosen the Correlated Topic Model for its ability to capture correlations between topics. According to the Correlated Topic Model, the contribution of a topic $z$ to a document $d$, $P(z|d)$, is drawn from a hierarchical model involving a correlated multivariate distribution \citep{Blei2007}:%instead of a Dirichlet distribution as is the case in the simpler LDA model \citep{Blei2007}:

\begin{align}
    \label{eq:ctm_prior}
    \vec{\beta}_{d} &\sim \mathcal{N}(\vec{\mu}, \Sigma) \\
    P(z|d) &= \dfrac{\exp \beta_{d,z}}{\sum_{i=1}^k \exp \beta_{d,i}}
\end{align}
